{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M8q1uMrRM_a"
      },
      "outputs": [],
      "source": [
        "from os import listdir\r\n",
        "from os.path import join, splitext\r\n",
        "\r\n",
        "from typing import Tuple\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.transforms import ToTensor, RandomHorizontalFlip, RandomVerticalFlip, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6OZnprYRVp-",
        "outputId": "744326ef-09c7-42bd-e6a9-9fd4af61d0c8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKhiiZplRXuK"
      },
      "outputs": [],
      "source": [
        "import os.path\r\n",
        "\r\n",
        "DATA_FOLDER = '/content/gdrive/My Drive/'\r\n",
        "TRAINING_SET_FOLDER = os.path.join(DATA_FOLDER, 'semantic_drone_dataset')\r\n",
        "\r\n",
        "#Resized version of the images stored on the disk\r\n",
        "INPUT_IMAGES_FOLDER = os.path.join(TRAINING_SET_FOLDER, 'resized_original250')\r\n",
        "LABEL_IMAGES_FOLDER = os.path.join(TRAINING_SET_FOLDER, 'resized_label250')\r\n",
        "\r\n",
        "TRAIN_CSV = os.path.join(DATA_FOLDER, 'train.csv')\r\n",
        "TEST_CSV = os.path.join(DATA_FOLDER, 'test.csv')\r\n",
        "VALIDATION_CSV = os.path.join(DATA_FOLDER, 'validation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1KiQdQZRbIg"
      },
      "outputs": [],
      "source": [
        "\"dataset: utility to access the data\"\r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "class CSVDataset(torch.utils.data.Dataset):\r\n",
        "    \"dataset for a subset of the raw dataset given by a csv file\"\r\n",
        "\r\n",
        "    def __init__(self, source, transform=None):\r\n",
        "        \"Initializes a dataset from a csv file created by split\"\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.transform = transform\r\n",
        "        if transform is None:\r\n",
        "            self.transform = lambda e: e\r\n",
        "\r\n",
        "        # get pd.Series containing all filename\r\n",
        "        self.imgs = pd.read_csv(source, names=('img',)).img\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.imgs)\r\n",
        "\r\n",
        "    def __getitem__(self, index: int):\r\n",
        "        \"returns the index-th data item of the dataset.\"\r\n",
        "        fname = self.imgs[index]\r\n",
        "        inpt = Image.open(join(INPUT_IMAGES_FOLDER, fname))\r\n",
        "        lbel = Image.open(join(LABEL_IMAGES_FOLDER, splitext(fname)[0]+'.png'))\r\n",
        "\r\n",
        "        return self.transform(inpt), self.transform(lbel), fname\r\n",
        "\r\n",
        "\r\n",
        "class SegmentationDataset(torch.utils.data.Dataset):\r\n",
        "    \"dataset holding images and their segmentation masks (greyscale)\"\r\n",
        "\r\n",
        "    def __init__(self, source: str, crop_size: Tuple[int, int], train: bool):\r\n",
        "        \"source: file path, crop_size: (width, height), train: true if training set\"\r\n",
        "        super().__init__()\r\n",
        "        self.images_transform = transforms.Compose(\r\n",
        "            [transforms.ToTensor(),\r\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n",
        "            ])\r\n",
        "        self.crop_h = crop_size[0]\r\n",
        "        self.crop_w = crop_size[1]\r\n",
        "\r\n",
        "        # get pd.Series containing all filename\r\n",
        "        self.imgs = pd.read_csv(source, names=('img',)).img\r\n",
        "        self.train = train\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.imgs)\r\n",
        "\r\n",
        "    def __getitem__(self, index: int):\r\n",
        "        \r\n",
        "        fname = self.imgs[index]\r\n",
        "        inpt = Image.open(join(INPUT_IMAGES_FOLDER, fname))\r\n",
        "        lbel = Image.open(join(LABEL_IMAGES_FOLDER, splitext(fname)[0] + '.png'))\r\n",
        "\r\n",
        "        if self.train:\r\n",
        "            crop_list = []\r\n",
        "            for _ in range(3):\r\n",
        "\r\n",
        "                try:\r\n",
        "                    #Random crop\r\n",
        "                    i, j, h, w = transforms.RandomCrop.get_params(\r\n",
        "                        inpt, output_size=(self.crop_h, self.crop_w) )\r\n",
        "                    image = transforms.functional.crop(inpt, i, j, h, w)\r\n",
        "                    mask = transforms.functional.crop(lbel, i, j, h, w)\r\n",
        "                    #Random horizontal flip\r\n",
        "                    r = random.random()\r\n",
        "                    if r > 0.5:\r\n",
        "                        image = transforms.functional.hflip(image)\r\n",
        "                        mask = transforms.functional.hflip(mask)\r\n",
        "                    \r\n",
        "                    crop_list.append( (self.images_transform(image), np.array(mask, dtype=np.int64)) )\r\n",
        "            \r\n",
        "                except ValueError:\r\n",
        "                    print(\"Could not crop the image\")\r\n",
        "                    print(\"Image is discarded from training set\")\r\n",
        "                    break\r\n",
        "            return crop_list\r\n",
        "        else:\r\n",
        "          inpt: torch.Tensor = self.images_transform(inpt)  # C, H, W\r\n",
        "          return inpt, np.array(lbel, dtype=np.int64), fname\r\n",
        "\r\n",
        "\r\n",
        "def trainset(size: Tuple[int, int]) -> CSVDataset:\r\n",
        "    \"trainset: returns the training set\"\r\n",
        "    return SegmentationDataset(TRAIN_CSV, size, train=True)\r\n",
        "\r\n",
        "\r\n",
        "def testset(size: Tuple[int, int]) -> CSVDataset:\r\n",
        "    \"trainset: returns the testing set\"\r\n",
        "    return SegmentationDataset(TEST_CSV, size, train=False)\r\n",
        "\r\n",
        "def validationset(size: Tuple[int, int] = (6000, 4000)) -> CSVDataset:\r\n",
        "    \"trainset: returns the validation set\"\r\n",
        "    return SegmentationDataset(VALIDATION_CSV, size)\r\n",
        "\r\n",
        "def split(test=0.1, validation=0.1):\r\n",
        "    df = pd.DataFrame(data=[f for f in listdir(\r\n",
        "        INPUT_IMAGES_FOLDER) if f.endswith(\"jpg\")])\r\n",
        "    df = df.sample(frac=1, random_state=42)\r\n",
        "\r\n",
        "    test_size = int(test * len(df))\r\n",
        "    validation_size = int(validation * len(df))\r\n",
        "    train_size = len(df) - test_size - validation_size\r\n",
        "\r\n",
        "    test_end = train_size + test_size\r\n",
        "    valid_end = test_end + validation_size\r\n",
        "\r\n",
        "    df.iloc[0:train_size].to_csv(TRAIN_CSV, index=False, header=False)\r\n",
        "    df.iloc[train_size:test_end].to_csv(TEST_CSV, index=False, header=False)\r\n",
        "    df.iloc[test_end:valid_end].to_csv(\r\n",
        "        VALIDATION_CSV, index=False, header=False)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSYsP7qiSaAO"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XIBiSD4JRhOq",
        "outputId": "5812e65d-4027-4fc3-e5a4-442738ccc1c3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "def conv(in_channels: int, out_channels: int) -> nn.Conv2d:\r\n",
        "    return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1), nn.BatchNorm2d(out_channels), nn.ReLU())\r\n",
        "\r\n",
        "def deconv(in_channels: int, out_channels: int) -> nn.Conv2d:\r\n",
        "    return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1), nn.BatchNorm2d(out_channels), nn.ReLU())\r\n",
        "\r\n",
        "class net(nn.Module):\r\n",
        "    \"Fully convolution neural network with a encoder based on VGG-16 architecture. Inspired from paper available on https://arxiv.org/abs/1505.04366\"\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(net, self).__init__()\r\n",
        "        \r\n",
        "\r\n",
        "        self.pool = nn.MaxPool2d((2, 2), stride=2, return_indices=True)\r\n",
        "        self.unpool = nn.MaxUnpool2d((2, 2))\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "        self.conv1 = conv(3, 64)#1\r\n",
        "        self.conv2 = conv(64, 64)#1\r\n",
        "        self.conv3 = conv(64, 128)#1\r\n",
        "        self.conv4 = conv(128, 128)#1\r\n",
        "        self.conv5 = conv(128, 256)#1\r\n",
        "        self.conv6 = conv(256, 256)#2\r\n",
        "        self.conv7 = conv(256, 512)#1\r\n",
        "        self.conv8 = conv(512, 512)#5\r\n",
        "        #--------------------Total=13\r\n",
        "\r\n",
        "        self.deconv8 = deconv(512, 512)\r\n",
        "        self.deconv7 = deconv(512, 256)\r\n",
        "        self.deconv6 = deconv(256, 256)\r\n",
        "        self.deconv5 = deconv(256, 128)\r\n",
        "        self.deconv4 = deconv(128, 128)\r\n",
        "        self.deconv3 = deconv(128, 64)\r\n",
        "        self.deconv2 = deconv(64, 64)\r\n",
        "        self.deconv1 = deconv(64, 26)\r\n",
        "                                 \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "\r\n",
        "        size1 = x.size()\r\n",
        "        x = self.conv2(self.conv1(x))\r\n",
        "        x, indices1 = self.pool(x)\r\n",
        "\r\n",
        "        size2 = x.size()\r\n",
        "        x = self.conv4(self.conv3(x))\r\n",
        "        x, indices2 = self.pool(x)\r\n",
        "\r\n",
        "        size3 = x.size()\r\n",
        "        x = self.conv6(self.conv6(self.conv5(x)))\r\n",
        "        x, indices3 = self.pool(x)\r\n",
        "\r\n",
        "        size4 = x.size()\r\n",
        "        x = self.conv8(self.conv8(self.conv7(x)))\r\n",
        "        x, indices4 = self.pool(x)\r\n",
        "\r\n",
        "        size5 = x.size()\r\n",
        "        x = self.conv8(self.conv8(self.conv8(x)))\r\n",
        "        x, indices5 = self.pool(x)\r\n",
        "\r\n",
        "\r\n",
        "        x = self.unpool(x, indices=indices5, output_size=size5)\r\n",
        "        x = self.deconv8(self.deconv8(self.deconv8(x)))\r\n",
        "\r\n",
        "        x = self.unpool(x, indices=indices4, output_size=size4)\r\n",
        "        x = self.deconv7(self.deconv8(self.deconv8(x)))\r\n",
        "\r\n",
        "        x = self.unpool(x, indices=indices3, output_size=size3)\r\n",
        "        x = self.deconv5(self.deconv6(self.deconv6(x)))\r\n",
        "\r\n",
        "        x = self.unpool(x, indices=indices2, output_size=size2)\r\n",
        "        x = self.deconv3(self.conv4(x))\r\n",
        "\r\n",
        "        x = self.unpool(x, indices=indices1, output_size=size1)\r\n",
        "        x = self.deconv1(self.conv2(x))\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "train_set = trainset((224, 224))\r\n",
        "test_set = testset((600, 300))\r\n",
        "\r\n",
        "train_ldr = torch.utils.data.DataLoader(\r\n",
        "    train_set, batch_size=4, shuffle=True, num_workers=2, pin_memory=True)\r\n",
        "test_ldr = torch.utils.data.DataLoader(\r\n",
        "    test_set, batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\r\n",
        "\r\n",
        "device = 'cuda:0'\r\n",
        "model = net().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "\r\n",
        "def train(num_epochs):\r\n",
        "    \"num_epochs: number of epochs used to train and test the model\"\r\n",
        "    \r\n",
        "    train_loss = torch.zeros((num_epochs), device=device)\r\n",
        "    test_loss = torch.zeros((num_epochs), device=device)\r\n",
        "    test_acc = torch.zeros((num_epochs), device=device)\r\n",
        "\r\n",
        "    for i in range(num_epochs):\r\n",
        "        print(f'epoch ({i+1:2}/{num_epochs:2})', end='\\r')\r\n",
        "        #Training the model\r\n",
        "        model.train()\r\n",
        "        print(\"Training\")\r\n",
        "        for m, l in enumerate(train_ldr):\r\n",
        "            print(\"Image \" + str(m+1))\r\n",
        "            for k, (x, y) in enumerate(l):\r\n",
        "              outputs = model(x.to(device))\r\n",
        "              loss = criterion(outputs, y.to(device))\r\n",
        "\r\n",
        "              train_loss[i] += loss.detach().sum()\r\n",
        "\r\n",
        "              optimizer.zero_grad()\r\n",
        "              loss.backward()\r\n",
        "              optimizer.step()\r\n",
        "\r\n",
        "        print('')\r\n",
        "        print(f'epoch {i+1:2}/{num_epochs:2} - evaluation')\r\n",
        "        with torch.no_grad():\r\n",
        "            model.eval()\r\n",
        "            #Testing the model\r\n",
        "            accuracy = 0.0\r\n",
        "            for x, y, _ in test_ldr:\r\n",
        "                \r\n",
        "                inputs = x.to(device)\r\n",
        "                targets = y.to(device)\r\n",
        "\r\n",
        "                outputs = model(inputs)\r\n",
        "\r\n",
        "                loss = criterion(outputs, targets)\r\n",
        "                test_loss[i] += loss.sum()\r\n",
        "\r\n",
        "                # per - pixel accuracy\r\n",
        "                predicted = outputs.argmax(1)\r\n",
        "                accuracy += (predicted == targets).float().mean()\r\n",
        "            test_acc[i] = accuracy / len(test_ldr)\r\n",
        "\r\n",
        "    train_loss /= (num_epochs * train_ldr.batch_size * len(train_ldr))\r\n",
        "    test_loss /= (num_epochs * test_ldr.batch_size * len(test_ldr))\r\n",
        "\r\n",
        "    return train_loss.cpu(), test_loss.cpu(), test_acc.cpu()\r\n",
        "\r\n",
        "\r\n",
        "num_epochs = 100\r\n",
        "print(f'training for {num_epochs} epochs')\r\n",
        "epochs_train_loss, epochs_test_loss, test_acc = train(num_epochs)\r\n",
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/VGG-FCN.pth\")\r\n",
        "\r\n",
        "print(f'{epochs_train_loss}\\n{epochs_test_loss}\\n{test_acc}')\r\n",
        "\r\n",
        "idx = range(0, num_epochs)\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(idx, epochs_train_loss, label='training loss')\r\n",
        "plt.plot(idx, epochs_test_loss, label='testing loss')\r\n",
        "plt.xlabel(\"epoch\")\r\n",
        "plt.ylabel(\"Cross-entropy loss\")\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "plt.savefig('content/gdrive/VGG-FCN.png')\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(idx, test_acc, 'k', label='testing accuracy')\r\n",
        "plt.xlabel(\"epoch\")\r\n",
        "plt.ylabel(\"Accuracy\")\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "plt.savefig('content/gdrive/VGG-FCN.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FCN.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0852ffa15271a5addd37f32ea18dbf1b0df402a47e230b8c481b506dfb20fbc5"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit (windows store)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}