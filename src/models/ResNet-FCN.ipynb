{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3STOHCLqDoTO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M8q1uMrRM_a"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import join, splitext\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Resize, RandomHorizontalFlip, RandomVerticalFlip, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj6fFfEeRTNh",
        "outputId": "e5223c26-32b4-43d8-c758-1cac4055ef25"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKhiiZplRXuK"
      },
      "outputs": [],
      "source": [
        "import os.path\r\n",
        "\r\n",
        "DATA_FOLDER = '/content/gdrive/My Drive/'\r\n",
        "TRAINING_SET_FOLDER = os.path.join(DATA_FOLDER, 'semantic_drone_dataset')\r\n",
        "INPUT_IMAGES_FOLDER = os.path.join(TRAINING_SET_FOLDER, 'resized_original224')\r\n",
        "LABEL_IMAGES_FOLDER = os.path.join(TRAINING_SET_FOLDER, 'resized_label224')\r\n",
        "TRAIN_CSV = os.path.join(DATA_FOLDER, 'train.csv')\r\n",
        "TEST_CSV = os.path.join(DATA_FOLDER, 'test.csv')\r\n",
        "VALIDATION_CSV = os.path.join(DATA_FOLDER, 'validation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1KiQdQZRbIg"
      },
      "outputs": [],
      "source": [
        "class CSVDataset(torch.utils.data.Dataset):\r\n",
        "    \"dataset for a subset of the raw dataset given by a csv file\"\r\n",
        "\r\n",
        "    def __init__(self, source, transform=None):\r\n",
        "        \"Initializes a dataset from a csv file created by split\"\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.transform = transform\r\n",
        "        if transform is None:\r\n",
        "            self.transform = lambda e: e\r\n",
        "\r\n",
        "        # get pd.Series containing all filename\r\n",
        "        self.imgs = pd.read_csv(source, names=('img',)).img\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.imgs)\r\n",
        "\r\n",
        "    def __getitem__(self, index: int):\r\n",
        "        \"returns the index-th data item of the dataset.\"\r\n",
        "        fname = self.imgs[index]\r\n",
        "        inpt = Image.open(join(INPUT_IMAGES_FOLDER, fname))\r\n",
        "        lbel = Image.open(join(LABEL_IMAGES_FOLDER, splitext(fname)[0]+'.png'))\r\n",
        "\r\n",
        "        return self.transform(inpt), self.transform(lbel), fname\r\n",
        "\r\n",
        "\r\n",
        "class SegmentationDataset(torch.utils.data.Dataset):\r\n",
        "    \"dataset holding images and their segmentation masks (greyscale)\"\r\n",
        "\r\n",
        "    def __init__(self, source: str, size: Tuple[int, int]):\r\n",
        "        \"source: file path, size: (width, height)\"\r\n",
        "        super().__init__()\r\n",
        "        self.images_transform = transforms.Compose(\r\n",
        "            [transforms.ToTensor(),\r\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n",
        "            ])\r\n",
        "\r\n",
        "        # get pd.Series containing all filename\r\n",
        "        self.imgs = pd.read_csv(source, names=('img',)).img\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.imgs)\r\n",
        "\r\n",
        "    def __getitem__(self, index: int):\r\n",
        "\r\n",
        "        fname = self.imgs[index]\r\n",
        "        inpt = Image.open(join(INPUT_IMAGES_FOLDER, fname))\r\n",
        "        lbel = Image.open(join(LABEL_IMAGES_FOLDER, splitext(fname)[0]+'.png'))\r\n",
        "\r\n",
        "        # apply transform\r\n",
        "        inpt: torch.Tensor = self.images_transform(inpt)  # C, H, W\r\n",
        "\r\n",
        "        return inpt, np.array(lbel, dtype=np.int64), fname\r\n",
        "\r\n",
        "\r\n",
        "def trainset(size: Tuple[int, int] = (6000, 4000)) -> CSVDataset:\r\n",
        "    \"trainset: returns the training set\"\r\n",
        "    return SegmentationDataset(TRAIN_CSV, size)\r\n",
        "\r\n",
        "\r\n",
        "def testset(size: Tuple[int, int] = (6000, 4000)) -> CSVDataset:\r\n",
        "    \"trainset: returns the testing set\"\r\n",
        "    return SegmentationDataset(TEST_CSV, size)\r\n",
        "\r\n",
        "\r\n",
        "def validationset(size: Tuple[int, int] = (6000, 4000)) -> CSVDataset:\r\n",
        "    \"trainset: returns the validation set\"\r\n",
        "    return SegmentationDataset(VALIDATION_CSV, size)\r\n",
        "\r\n",
        "def split(test=0.1, validation=0.1):\r\n",
        "    df = pd.DataFrame(data=[f for f in listdir(\r\n",
        "        INPUT_IMAGES_FOLDER) if f.endswith(\"jpg\")])\r\n",
        "    df = df.sample(frac=1, random_state=42)\r\n",
        "\r\n",
        "    test_size = int(test * len(df))\r\n",
        "    validation_size = int(validation * len(df))\r\n",
        "    train_size = len(df) - test_size - validation_size\r\n",
        "\r\n",
        "    test_end = train_size + test_size\r\n",
        "    valid_end = test_end + validation_size\r\n",
        "\r\n",
        "    df.iloc[0:train_size].to_csv(TRAIN_CSV, index=False, header=False)\r\n",
        "    df.iloc[train_size:test_end].to_csv(TEST_CSV, index=False, header=False)\r\n",
        "    df.iloc[test_end:valid_end].to_csv(\r\n",
        "        VALIDATION_CSV, index=False, header=False)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSYsP7qiSaAO"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XIBiSD4JRhOq",
        "outputId": "bbb91460-309d-4e1d-82ca-7d6fa9e18726"
      },
      "outputs": [],
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "def conv(in_channels: int, out_channels: int, kernel_size=3) -> nn.Conv2d:\r\n",
        "    return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, padding=1), nn.BatchNorm2d(out_channels), nn.ReLU())\r\n",
        "\r\n",
        "def deconv(in_channels: int, out_channels: int) -> nn.Conv2d:\r\n",
        "    return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, padding=1, stride=2), nn.BatchNorm2d(out_channels), nn.ReLU())\r\n",
        "\r\n",
        "class net(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(net, self).__init__()\r\n",
        "        \r\n",
        "        torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\r\n",
        "        self.resnet = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True) #1000 classes\r\n",
        "        self.resnet= torch.nn.Sequential(*list(self.resnet.children())[:-2])\r\n",
        "        #from 1000 classes to nb of classes for semantic segmentation problem\r\n",
        "        self.net = nn.Sequential(self.resnet, deconv(2048, 1024), deconv(1024, 512), deconv(512, 256), deconv(256, 128), deconv(128, 26))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self.net(x)\r\n",
        "\r\n",
        "\r\n",
        "train_set = trainset((224, 224))\r\n",
        "test_set = testset((224, 224))\r\n",
        "\r\n",
        "train_ldr = torch.utils.data.DataLoader(\r\n",
        "    train_set, batch_size=4, shuffle=True, num_workers=2, pin_memory=True)\r\n",
        "test_ldr = torch.utils.data.DataLoader(\r\n",
        "    test_set, batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\r\n",
        "\r\n",
        "device = 'cuda:0'\r\n",
        "model = net().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "\r\n",
        "\r\n",
        "def train(num_epochs):\r\n",
        "    \r\n",
        "    train_loss = torch.zeros((num_epochs), device=device)\r\n",
        "    test_loss = torch.zeros((num_epochs), device=device)\r\n",
        "    test_acc = torch.zeros((num_epochs), device=device)\r\n",
        "\r\n",
        "    for i in range(num_epochs):\r\n",
        "        print(f'epoch ({i+1:2}/{num_epochs:2})', end='\\r')\r\n",
        "        model.train()\r\n",
        "        for k, (x, y, _) in enumerate(train_ldr):\r\n",
        "            print(\"Image \" + str(k))\r\n",
        "            print(f'epoch ({i+1:2}/{num_epochs:2}) - batch ({k+1:3}/{len(train_ldr):3})', end='\\r')\r\n",
        "            outputs = model(x.to(device))\r\n",
        "            loss = criterion(outputs, y.to(device))\r\n",
        "\r\n",
        "            train_loss[i] += loss.detach().sum()\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "        print('')\r\n",
        "        print(f'epoch {i+1:2}/{num_epochs:2} - evaluation')\r\n",
        "        with torch.no_grad():\r\n",
        "            model.eval()\r\n",
        "            accuracy = 0.0\r\n",
        "            for x, y, _ in test_ldr:\r\n",
        "                \r\n",
        "                inputs = x.to(device)\r\n",
        "                targets = y.to(device)\r\n",
        "\r\n",
        "                outputs = model(inputs)\r\n",
        "\r\n",
        "                loss = criterion(outputs, targets)\r\n",
        "                test_loss[i] += loss.sum()\r\n",
        "\r\n",
        "                # per - pixel accuracy\r\n",
        "                predicted = outputs.argmax(1)\r\n",
        "                accuracy += (predicted == targets).float().mean()\r\n",
        "            test_acc[i] = accuracy / len(test_ldr)\r\n",
        "\r\n",
        "    train_loss /= (num_epochs * train_ldr.batch_size * len(train_ldr))\r\n",
        "    test_loss /= (num_epochs * test_ldr.batch_size * len(test_ldr))\r\n",
        "\r\n",
        "    return train_loss.cpu(), test_loss.cpu(), test_acc.cpu()\r\n",
        "\r\n",
        "\r\n",
        "num_epochs = 100  # could be increased but training is long\r\n",
        "print(f'training for {num_epochs} epochs')\r\n",
        "epochs_train_loss, epochs_test_loss, test_acc = train(num_epochs)\r\n",
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/ResNet2.pth\")\r\n",
        "\r\n",
        "print(f'{epochs_train_loss}\\n{epochs_test_loss}\\n{test_acc}')\r\n",
        "\r\n",
        "idx = range(0, num_epochs)\r\n",
        "plt.figure()\r\n",
        "plt.plot(idx, epochs_train_loss, label='training loss')\r\n",
        "plt.plot(idx, epochs_test_loss, label='testing loss')\r\n",
        "plt.xlabel(\"epoch\")\r\n",
        "plt.ylabel(\"loss\")\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "plt.savefig('content/gdrive/MyDrive/ResNetLosses.png')\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(idx, test_acc, 'k', label='testing accuracy')\r\n",
        "plt.xlabel(\"epoch\")\r\n",
        "plt.ylabel(\"accuracy\")\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "plt.savefig('content/gdrive/MyDrive/ResAccuracy.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ResNet_2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0852ffa15271a5addd37f32ea18dbf1b0df402a47e230b8c481b506dfb20fbc5"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit (windows store)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}